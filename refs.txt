[1]J. J. Spilker Jr, P. Axelrad, B. W. Parkinson, and P. Enge, Global positioning system: theory and applications, volume I. Reston, Virginia: American Institute of Aeronautics, 1996.
[2]S. Schaer, Mapping and predicting the Earth’s ionosphere using the Global Positioning System, vol. 59. Zürich: Institut für Geodäsie und Photogrammetrie, Eidg. Technische Hochschule, 1999.
[3]M. Durmaz and M. O. Karslioglu, “Regional vertical total electron content (VTEC) modeling together with satellite and receiver differential code biases (DCBs) using semi-parametric multivariate adaptive regression B-splines (SP-BMARS),” Journal of Geodesy, vol. 89, pp. 347–360, 2015, doi: 10.1007/s00190-014-0779-8.
[4]R. Jin, S. Jin, and G. Feng, “M_DCB: Matlab code for estimating GNSS satellite and receiver differential code biases,” GPS solutions, vol. 16, no. 4, pp. 541–548, 2012, doi: 10.1007/s10291-012-0279-3.
[5]K. Davies, Ionospheric Radio. Futures Place, Stevenage: Institution of Engineering & Technology, 1990. [Online]. Available: https://books.google.hr/books?id=qdWUKSj5PCcC
[6]J. Y. Liu et al., “Seismoionospheric GPS total electron content anomalies observed before the 12 May 2008 Mw7. 9 Wenchuan earthquake,” Journal of Geophysical Research: Space Physics, vol. 114, no. A4, 2009, doi: 10.1029/2008JA013698.
[7]G. Prölss, Physics of the Earth’s space environment: an introduction. Berlin/Heidelberg, Germany: Springer Science & Business Media, 2012.
[8]A. Oxley, Uncertainties in GPS Positioning: A mathematical discourse. Cambridge, Massachusetts: Academic Press, 2017.
[9]G. K. Seemala, “Chapter 4 - Estimation of ionospheric total electron content (TEC) from GNSS observations,” in Atmospheric Remote Sensing, A. K. Singh and S. Tiwari, Eds. Amsterdam, Netherlands: Elsevier, 2023, pp. 63–84. doi: 10.1016/B978-0-323-99262-6.00022-5.
[10]J. A. Klobuchar, “Ionospheric time-delay algorithm for single-frequency GPS users,” IEEE Transactions on aerospace and electronic systems, pp. 325–331, 1987, doi: 10.1109/TAES.1987.310829.
[11]P. K. Enge, “The global positioning system: Signals, measurements, and performance,” International Journal of Wireless Information Networks, vol. 1, pp. 83–105, 1994, doi: 10.1007/BF02106512.
[12]R. Filjar, I. Hedji, J. Prpić-Oršić, and T. Iliev, “An Ambient Adaptive Global Navigation Satellite System Total Electron Content Predictive Model for Short-Term Rapid Geomagnetic Storm Events,” Remote Sensing, vol. 16, no. 16, p. 3051, 2024, doi: 10.3390/rs16163051.
[13]R. Natras, B. Soja, and M. Schmidt, “Ensemble machine learning of random forest, AdaBoost and XGBoost for vertical total electron content forecasting,” Remote Sensing, vol. 14, no. 15, p. 3547, 2022, doi: 10.3390/rs14153547.
[14]R. Natras et al., “Regional ionosphere delay models based on CORS data and machine learning,” NAVIGATION: Journal of the Institute of Navigation, vol. 70, no. 3, 2023, doi: 10.33012/navi.577.
[15]INTERMAGNET and others, “Intermagnet reference data set (IRDS) 2019 – definitive magnetic observatory data,” GFZ Data Services, 2022, doi: 10.5880/INTERMAGNET.1991.2019.
[16]M. Kuhn, “caret: Classification and Regression Training,” CRAN: Contributed Packages, Oct. 2007, doi: 10.32614/cran.package.caret.
[17]M. Kuhn, “Building predictive models in R using the caret package,” Journal of statistical software, vol. 28, pp. 1–26, 2008, doi: 10.18637/jss.v028.i05.
[18]M. Kuhn, Applied predictive modeling. Berlin/Heidelberg, Germany: Springer, 2013.
[19]B. E. Boser, I. M. Guyon, and V. N. Vapnik, “A training algorithm for optimal margin classifiers,” in Proceedings of the fifth annual workshop on Computational learning theory, Jul. 1992, pp. 144–152. doi: 10.1145/130385.130401.
[20]T. Hastie, S. Rosset, J. Zhu, and H. Zou, “Multi-class AdaBoost,” Stat. Interface, vol. 2, no. 3, pp. 349–360, 2009, doi: 10.4310/SII.2009.v2.n3.a8.
[21]D. Meyer, F. Leisch, and K. Hornik, “The support vector machine under test,” Neurocomputing, vol. 55, no. 1–2, pp. 169–186, Sep. 2003, doi: 10.1016/S0925-2312(03)00431-4.
[22]W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery, Numerical recipes 3rd edition, Third. Cambridge, England: Cambridge University Press, 2007.
[23]X. Wu et al., “Top 10 algorithms in data mining,” Knowl. Inf. Syst., vol. 14, no. 1, pp. 1–37, Jan. 2008, doi: 10.1007/s10115-007-0114-2.
[24]S. Shalev-Shwartz and S. Ben-David, “Decision Trees,” in Understanding Machine Learning: From Theory to Algorithms, Cambridge, England: Cambridge University Press, 2014, pp. 212–218. doi: 10.1017/CBO9781107298019.019.
[25]D. J. Hand and K. Yu, “Idiot’s Bayes: Not So Stupid after All?,” Int. Stat. Rev., vol. 69, no. 3, p. 385, Dec. 2001, doi: 10.1111/j.1751-5823.2001.tb00465.x.
[26]S. J. Russell and P. Norvig, Artificial intelligence: a modern approach. London, England: Pearson, 2016.
[27]R. Caruana and A. Niculescu-Mizil, “An Empirical Comparison of Supervised Learning Algorithms,” Proceedings of the 23rd international conference on Machine learning - ICML ’06, vol. 2006, pp. 161–168, Jun. 2006, doi: 10.1145/1143844.1143865.
[28]G. H. John and P. Langley, “Estimating Continuous Distributions in Bayesian Classifiers,” arXiv preprint arXiv:1302.4964, 2013, doi: 10.48550/arXiv.1302.4964.
[29]M. N. Murty and V. S. Devi, Pattern recognition: An algorithmic approach. Berlin/Heidelberg, Germany: Springer Science & Business Media, 2011.
[30]A. Brahme, Comprehensive biomedical physics. 8-11 Southampton Street, London: Newnes, 2014.
[31]J. D. Olden and D. A. Jackson, “Illuminating the ‘black box’: a randomization approach for understanding variable contributions in artificial neural networks,” Ecological modelling, vol. 154, no. 1–2, pp. 135–150, 2002, doi: 10.1016/S0304-3800(02)00064-9.
[32]C. Bishop, Pattern Recognition and Machine Learning. Berlin/Heidelberg, Germany: Springer, 2006.
[33]V. Vapnik, The nature of statistical learning theory. Berlin/Heidelberg, Germany: Springer science & business media, 2013.
[34]I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning. Cambridge, Massachusetts: MIT Press, 2016.
[35]P. Probst, A. L. Boulesteix, and B. Bischl, “Tunability: Importance of hyperparameters of machine learning algorithms,” Journal of Machine Learning Research, vol. 20, no. 53, pp. 1–32, 2019, doi: 10.48550/arXiv.1802.09596.
[36]F. M. Stewart, Introduction to linear algebra. Mineola, New York, United States of America: Courier Dover Publications, 2019.
[37]I. T. Jolliffe and J. Cadima, “Principal component analysis: a review and recent developments,” Philosophical transactions of the royal society A: Mathematical, Physical and Engineering Sciences, vol. 374, no. 2065, p. 20150202, 2016, doi: 10.1098/rsta.2015.0202.
[38]H. Abdi, “Partial least squares regression and projection on latent structure regression (PLS Regression),” Wiley interdisciplinary reviews: computational statistics, vol. 2, no. 1, pp. 97–106, 2010, doi: 10.1002/wics.51.
[39]S. Sæbø, T. Almøy, A. Flatberg, A. H. Aastveit, and H. Martens, “LPLS-regression: a method for prediction and classification under the influence of background information on predictor variables,” Chemometrics and Intelligent Laboratory Systems, vol. 91, no. 2, pp. 121–132, 2008, doi: 10.1016/j.chemolab.2007.10.006.
[40]V. González, R. Giraldo, and V. Leiva, “PLS1-MD: A partial least squares regression algorithm for solving missing data problems,” Chemometrics and Intelligent Laboratory Systems, vol. 240, p. 104876, 2023, doi: 10.1016/j.chemolab.2023.104876.
[41]G. J. McLachlan, Discriminant analysis and statistical pattern recognition. Hoboken, New Jersey, United States of America: John Wiley & Sons, 2005. doi: 10.1002/0471725293.
[42]T. Hastie, R. Tibshirani, J. H. Friedman, and J. H. Friedman, The elements of statistical learning: data mining, inference, and prediction, vol. 2. Berlin/Heidelberg, Germany: Springer, 2009.
[43]C. Reynès, R. Sabatier, and N. Molinari, “Choice of B-splines with free parameters in the flexible discriminant analysis context,” Computational statistics & data analysis, vol. 51, no. 3, pp. 1765–1778, 2006, doi: 10.1016/j.csda.2005.11.018.
[44]D. Wetcher-Hendricks, Analyzing quantitative data: An introduction for social researchers. Hoboken, New Jersey, United States of America: John Wiley & Sons, 2011.
[45]J. Cohen, P. Cohen, S. G. West, and L. S. Aiken, Applied multiple regression/correlation analysis for the behavioral sciences. Milton Park, Abingdon-on-Thames, Oxfordshire, England, United Kingdom: Routledge, 2013.
[46]B. Zolesi and Lj. R. Cander, Ionospheric prediction and forecasting. Berlin/Heidelberg, Germany: Springer, 2014.
[47]P. I. Vellinov, C. W. Spassov, and S. I. Kolev, “Ionospheric effects of lightning during the increasing part of solar cycle 22,” Journal of atmospheric and terrestrial physics, vol. 54, no. 10, pp. 1347–1353, 1992, doi: 10.1016/0021-9169(92)90044-L.
[48]M. Liu, G. Luo, and H. Wang, “The 2013 Lushan earthquake in China tests hazard assessments,” Seismological Research Letters, vol. 85, no. 1, pp. 40–43, 2014, doi: 10.1785/0220130117.
[49]R. Schwenn, “Solar wind: Global properties,” in Encyclopedia of Astronomy & Astrophysics, Boca Raton, Florida, United States of America: CRC Press, 2001, pp. 1–9. doi: 10.1888/0333750888/2301.
[50]H. Bojinov, Y. Michalevsky, G. Nakibly, and D. Boneh, “Mobile Device Identification via Sensor Fingerprinting,” arXiv preprint arXiv:1408.1416, 2014, doi: 10.48550/arxiv.1408.1416.
[51]L. M. M. Myint, K. Hozumi, S. Saito, and P. Supnithi, “Analysis of local geomagnetic index under the influence of equatorial electrojet (EEJ) at the equatorial Phuket geomagnetic station in Thailand,” Advances in Space Research, vol. 70, no. 5, pp. 1429–1440, 2022, doi: 10.1016/j.asr.2022.06.024.
[52]J. Matzka, O. Bronkalla, K. Tornow, K. Elger, and C. Stolle, “Geomagnetic Kp index,” GFZ Data Services, 2021, doi: 10.5880/Kp.0001.
[53]J. Matzka, C. Stolle, Y. Yamazaki, O. Bronkalla, and A. Morschhauser, “The geomagnetic KP index and derived indices of geomagnetic activity,” Space Weather, vol. 19, no. 5, May 2021, doi: 10.1029/2020SW002641.
[54]C. A. Loewe and G. W. Prölss, “Classification and mean behavior of magnetic storms,” Journal of Geophysical Research: Space Physics, vol. 102, no. A7, pp. 14209–14213, 1997, doi: 10.1029/96JA04020.
[55]W. D. Gonzalez et al., “What is a geomagnetic storm?,” Journal of Geophysical Research: Space Physics, vol. 99, no. A4, pp. 5771–5792, 1994, doi: 10.1029/93JA02867.
[56]Y. Kamide et al., “Two-step development of geomagnetic storms,” Journal of Geophysical Research: Space Physics, vol. 103, no. A4, pp. 6917–6921, 1998, doi: 10.1029/97JA03337.
[57]A. Rozhnoi, M. S. Solovieva, O. A. Molchanov, and M. Hayakawa, “Middle latitude LF (40 kHz) phase variations associated with earthquakes for quiet and disturbed geomagnetic conditions,” Physics and Chemistry of the Earth, Parts A/B/C, vol. 29, no. 4–9, pp. 589–598, 2004, doi: 10.1016/j.pce.2003.08.061.
[58]M. E. Contadakis, D. N. Arabelos, C. Pikridas, and S. D. Spatalas, “Total electron content variations over southern Europe before and during the M 6.3 Abruzzo earthquake of April 6, 2009,” Annals of geophysics, vol. 55, no. 1, 2012, doi: 10.4401/ag-5322.
[59]R. E. Fan, K. W. Chang, C. J. Hsieh, X. R. Wang, and C. J. Lin, “LIBLINEAR: a library for large linear classification,” Journal of Machine Learning Research, vol. 9, pp. 1871–1874, Aug. 2008, doi: 10.1145/1390681.1442794.
[60]I. B. Mohamad and D. Usman, “Standardization and its effects on K-means clustering algorithm,” Research Journal of Applied Sciences, Engineering and Technology, vol. 6, no. 17, pp. 3299–3303, Sep. 2013, doi: 10.19026/rjaset.6.3638.
[61]P. G. Fennell, Z. Zuo, and K. Lerman, “Predicting and explaining behavioral data with structured feature space decomposition,” EPJ Data Sci., vol. 8, no. 1, Dec. 2019, doi: 10.48550/arXiv.1810.09841.
[62]M. Fagerland, S. Lydersen, and P. Laake, Statistical Analysis of Contingency Tables. Boca Raton, Florida: Chapman, 2017.
[63]S. C. Chow, J. Shao, H. Wang, and Y. Lokhnygina, Sample Size Calculations in Clinical Research. Boca Raton, Florida: Chapman, 2018.
[64]A. L. Edwards, “Note on the ‘correction for continuity’ in testing the significance of the difference between correlated proportions,” Psychometrika, vol. 13, no. 3, pp. 185–187, 1948, doi: 10.1007/BF02289261.
[65]H. Zhang, “The Optimality of Naive Bayes,” in Proceedings of the Seventeenth International Florida Artificial Intelligence Research Society Conference, FLAIRS 2004, Jan. 2004, vol. 2.
[66]V. Metsis, I. Androutsopoulos, and G. Paliouras, “Spam Filtering with Naive Bayes - Which Naive Bayes?,” Jan. 2006.
[67]A. Mccallum and K. Nigam, “A Comparison of Event Models for Naive Bayes Text Classification,” Work Learn Text Categ, vol. 752, May 2001.
