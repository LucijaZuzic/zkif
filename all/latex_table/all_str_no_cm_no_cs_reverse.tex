\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{7}{c|}{Statistics} \\ \hline
		Sen & Spec & PPV & NPV & DR & DP & BA \\ \hline
		$0\%$ & $100\%$ & NaN & $99.8123\%$ & $0\%$ & $0\%$ & $50\%$ \\ \hline
		$94.19\%$ & $39.95\%$ & $81.09\%$ & $71.55\%$ & $68.96\%$ & $85.04\%$ & $67.07\%$ \\ \hline
		$96.296\%$ & $95.417\%$ & $26.531\%$ & $99.933\%$ & $1.627\%$ & $6.133\%$ & $95.857\%$ \\ \hline
		$20.844\%$ & $100\%$ & $100\%$ & $80.25\%$ & $4.944\%$ & $4.944\%$ & $60.422\%$ \\ \hline
		$100\%$ & $97.277\%$ & $30.645\%$ & $100\%$ & $1.189\%$ & $3.88\%$ & $98.638\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the polynomial SVM model when using all variables as input.}
	\label{tab:cs:all:svmPoly}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{7}{c|}{Statistics} \\ \hline
		Sen & Spec & PPV & NPV & DR & DP & BA \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $0.1877\%$ & $0.1877\%$ & $100\%$ \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $73.22\%$ & $73.22\%$ & $100\%$ \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $1.69\%$ & $1.69\%$ & $100\%$ \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $23.72\%$ & $23.72\%$ & $100\%$ \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $1.189\%$ & $1.189\%$ & $100\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the decision tree model when using all variables as input.}
	\label{tab:cs:all:C5.0}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{7}{c|}{Statistics} \\ \hline
		Sen & Spec & PPV & NPV & DR & DP & BA \\ \hline
		$100\%$ & $99.9373\%$ & $75\%$ & $100\%$ & $0.1877\%$ & $0.2503\%$ & $99.9687\%$ \\ \hline
		$99.23\%$ & $99.53\%$ & $99.83\%$ & $97.93\%$ & $72.65\%$ & $72.78\%$ & $99.38\%$ \\ \hline
		$96.296\%$ & $99.554\%$ & $78.788\%$ & $99.936\%$ & $1.627\%$ & $2.065\%$ & $97.925\%$ \\ \hline
		$98.94\%$ & $99.75\%$ & $99.21\%$ & $99.67\%$ & $23.47\%$ & $23.65\%$ & $99.35\%$ \\ \hline
		$100\%$ & $99.937\%$ & $95\%$ & $100\%$ & $1.189\%$ & $1.252\%$ & $99.968\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the naive Bayes model when using all variables as input.}
	\label{tab:cs:all:nb}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{7}{c|}{Statistics} \\ \hline
		Sen & Spec & PPV & NPV & DR & DP & BA \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $0.1877\%$ & $0.1877\%$ & $100\%$ \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $73.22\%$ & $73.22\%$ & $100\%$ \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $1.69\%$ & $1.69\%$ & $100\%$ \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $23.72\%$ & $23.72\%$ & $100\%$ \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $1.189\%$ & $1.189\%$ & $100\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the neural network model when using all variables as input.}
	\label{tab:cs:all:nnet}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{7}{c|}{Statistics} \\ \hline
		Sen & Spec & PPV & NPV & DR & DP & BA \\ \hline
		$0\%$ & $100\%$ & NaN & $99.8123\%$ & $0\%$ & $0\%$ & $50\%$ \\ \hline
		$99.74\%$ & $71.73\%$ & $90.61\%$ & $99.03\%$ & $73.03\%$ & $80.6\%$ & $85.74\%$ \\ \hline
		$0\%$ & $100\%$ & NaN & $98.31\%$ & $0\%$ & $0\%$ & $50\%$ \\ \hline
		$75.2\%$ & $97.95\%$ & $91.94\%$ & $92.7\%$ & $17.83\%$ & $19.4\%$ & $86.57\%$ \\ \hline
		$0\%$ & $100\%$ & NaN & $98.811\%$ & $0\%$ & $0\%$ & $50\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the PLS model when using all variables as input.}
	\label{tab:cs:all:pls}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{7}{c|}{Statistics} \\ \hline
		Sen & Spec & PPV & NPV & DR & DP & BA \\ \hline
		$66.6667\%$ & $99.8746\%$ & $50\%$ & $99.9373\%$ & $0.1252\%$ & $0.2503\%$ & $83.2706\%$ \\ \hline
		$95.9\%$ & $85.51\%$ & $94.76\%$ & $88.41\%$ & $70.21\%$ & $74.09\%$ & $90.71\%$ \\ \hline
		$62.963\%$ & $99.363\%$ & $62.963\%$ & $99.363\%$ & $1.064\%$ & $1.69\%$ & $81.163\%$ \\ \hline
		$83.38\%$ & $96.55\%$ & $88.27\%$ & $94.92\%$ & $19.77\%$ & $22.4\%$ & $89.97\%$ \\ \hline
		$68.4211\%$ & $99.24\%$ & $52\%$ & $99.6186\%$ & $0.8135\%$ & $1.5645\%$ & $83.8305\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the FDA model when using all variables as input.}
	\label{tab:cs:all:fda}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{7}{c|}{Statistics} \\ \hline
		Sen & Spec & PPV & NPV & DR & DP & BA \\ \hline
		$0\%$ & $100\%$ & NaN & $99.8123\%$ & $0\%$ & $0\%$ & $50\%$ \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $73.22\%$ & $73.22\%$ & $100\%$ \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $1.69\%$ & $1.69\%$ & $100\%$ \\ \hline
		$100\%$ & $99.92\%$ & $99.74\%$ & $100\%$ & $23.72\%$ & $23.78\%$ & $99.96\%$ \\ \hline
		$94.737\%$ & $99.81\%$ & $85.714\%$ & $99.937\%$ & $1.126\%$ & $1.314\%$ & $97.273\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the PCA neural network model when using all variables as input.}
	\label{tab:cs:all:pcaNNet}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Model & elapsed \\ \hline
		svmPoly & $102.87$ \\ \hline
		C5.0 & $168.39$ \\ \hline
		nb & $189.80$ \\ \hline
		nnet & $493.97$ \\ \hline
		pls & $48.86$ \\ \hline
		fda & $50.66$ \\ \hline
		pcaNNet & $291.40$ \\ \hline
	\end{tabular}
	\caption{The train time in seconds for each model when using all variables as input.}
	\label{tab:time:all:train}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		Model & svmPoly & C5.0 & nb & nnet & pls & fda & pcaNNet \\ \hline
		elapsed & $102.87$ & $168.39$ & $189.80$ & $493.97$ & $48.86$ & $50.66$ & $291.40$ \\ \hline
	\end{tabular}
	\caption{The train time in seconds for each model when using all variables as input.}
	\label{tab:time:reverse:all:train}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Model & elapsed \\ \hline
		svmPoly & $0.16$ \\ \hline
		C5.0 & $0.08$ \\ \hline
		nb & $1.72$ \\ \hline
		nnet & $0.01$ \\ \hline
		pls & $0.25$ \\ \hline
		fda & $0.01$ \\ \hline
		pcaNNet & $0.01$ \\ \hline
	\end{tabular}
	\caption{The prediction time in seconds for each model when using all variables as input.}
	\label{tab:time:all:predict}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		Model & svmPoly & C5.0 & nb & nnet & pls & fda & pcaNNet \\ \hline
		elapsed & $0.16$ & $0.08$ & $1.72$ & $0.01$ & $0.25$ & $0.01$ & $0.01$ \\ \hline
	\end{tabular}
	\caption{The prediction time in seconds for each model when using all variables as input.}
	\label{tab:time:reverse:all:predict}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Model & elapsed \\ \hline
		svmPoly & NA \\ \hline
		C5.0 & $0.00$ \\ \hline
		nb & NA \\ \hline
		nnet & NA \\ \hline
		pls & $0.06$ \\ \hline
		fda & $0.05$ \\ \hline
		pcaNNet & NA \\ \hline
	\end{tabular}
	\caption{The variable importance calculation time in seconds for each model when using all variables as input.}
	\label{tab:time:all:importance}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		Model & svmPoly & C5.0 & nb & nnet & pls & fda & pcaNNet \\ \hline
		elapsed & NA & $0.00$ & NA & NA & $0.06$ & $0.05$ & NA \\ \hline
	\end{tabular}
	\caption{The variable importance calculation time in seconds for each model when using all variables as input.}
	\label{tab:time:reverse:all:importance}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Model & elapsed \\ \hline
		svmPoly & $103.52$ \\ \hline
		C5.0 & $169.28$ \\ \hline
		nb & $192.05$ \\ \hline
		nnet & $494.53$ \\ \hline
		pls & $49.99$ \\ \hline
		fda & $51.57$ \\ \hline
		pcaNNet & $291.98$ \\ \hline
	\end{tabular}
	\caption{The execution time in seconds for each model when using all variables as input.}
	\label{tab:time:all:total}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		Model & svmPoly & C5.0 & nb & nnet & pls & fda & pcaNNet \\ \hline
		elapsed & $103.52$ & $169.28$ & $192.05$ & $494.53$ & $49.99$ & $51.57$ & $291.98$ \\ \hline
	\end{tabular}
	\caption{The execution time in seconds for each model when using all variables as input.}
	\label{tab:time:reverse:all:total}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		Model & elapsed_train & elapsed_predict & elapsed_importance & elapsed_total \\ \hline
		svmPoly & $102.87$ & $0.16$ & NA & $103.52$ \\ \hline
		C5.0 & $168.39$ & $0.08$ & $0.00$ & $169.28$ \\ \hline
		nb & $189.80$ & $1.72$ & NA & $192.05$ \\ \hline
		nnet & $493.97$ & $0.01$ & NA & $494.53$ \\ \hline
		pls & $48.86$ & $0.25$ & $0.06$ & $49.99$ \\ \hline
		fda & $50.66$ & $0.01$ & $0.05$ & $51.57$ \\ \hline
		pcaNNet & $291.40$ & $0.01$ & NA & $291.98$ \\ \hline
	\end{tabular}
	\caption{The time taken for all algorithm stages in seconds for each model when using all variables as input.}
	\label{tab:time:all}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		Model & svmPoly & C5.0 & nb & nnet & pls & fda & pcaNNet \\ \hline
		elapsed_train & $102.87$ & $168.39$ & $189.80$ & $493.97$ & $48.86$ & $50.66$ & $291.40$ \\ \hline
		elapsed_predict & $0.16$ & $0.08$ & $1.72$ & $0.01$ & $0.25$ & $0.01$ & $0.01$ \\ \hline
		elapsed_importance & NA & $0.00$ & NA & NA & $0.06$ & $0.05$ & NA \\ \hline
		elapsed_total & $103.52$ & $169.28$ & $192.05$ & $494.53$ & $49.99$ & $51.57$ & $291.98$ \\ \hline
	\end{tabular}
	\caption{The time taken for all algorithm stages in seconds for each model when using all variables as input.}
	\label{tab:time:reverse:all}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		Metric & svmPoly & C5.0 & nb & nnet & pls & fda & pcaNNet \\ \hline
		Acc & $0.7672$ & $1$ & $0.9912$ & $1$ & $0.9086$ & $0.9199$ & $0.9975$ \\ \hline
		$95\%$ CI & $(0.7457, 0.7877)$ & $(0.9977, 1)$ & $(0.9853, 0.9952)$ & $(0.9977, 1)$ & $(0.8934, 0.9223)$ & $(0.9055, 0.9327)$ & $(0.9936, 0.9993)$ \\ \hline
		NIR & $0.7322$ & $0.7322$ & $0.7322$ & $0.7322$ & $0.7322$ & $0.7322$ & $0.7322$ \\ \hline
		$p$-value & $0.0007444$ & $< 2.2 \times {10}^{-16}$ & $< 2.2 \times {10}^{-16}$ & $< 2.2 \times {10}^{-16}$ & $< 2.2 \times {10}^{-16}$ & $< 2.2 \times {10}^{-16}$ & $< 2.2 \times {10}^{-16}$ \\ \hline
		Kappa & $0.3607$ & $1$ & $0.9787$ & $1$ & $0.7489$ & $0.8017$ & $0.9939$ \\ \hline
	\end{tabular}
	\caption{The accuracy, CI, NIR, $p$-value, and Kappa statistic for each model when using all variables as input.}
	\label{tab:stats:all}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		Model & Acc & $95\%$ CI & NIR & $p$-value & Kappa \\ \hline
		svmPoly & $0.7672$ & $(0.7457, 0.7877)$ & $0.7322$ & $0.0007444$ & $0.3607$ \\ \hline
		C5.0 & $1$ & $(0.9977, 1)$ & $0.7322$ & $< 2.2 \times {10}^{-16}$ & $1$ \\ \hline
		nb & $0.9912$ & $(0.9853, 0.9952)$ & $0.7322$ & $< 2.2 \times {10}^{-16}$ & $0.9787$ \\ \hline
		nnet & $1$ & $(0.9977, 1)$ & $0.7322$ & $< 2.2 \times {10}^{-16}$ & $1$ \\ \hline
		pls & $0.9086$ & $(0.8934, 0.9223)$ & $0.7322$ & $< 2.2 \times {10}^{-16}$ & $0.7489$ \\ \hline
		fda & $0.9199$ & $(0.9055, 0.9327)$ & $0.7322$ & $< 2.2 \times {10}^{-16}$ & $0.8017$ \\ \hline
		pcaNNet & $0.9975$ & $(0.9936, 0.9993)$ & $0.7322$ & $< 2.2 \times {10}^{-16}$ & $0.9939$ \\ \hline
	\end{tabular}
	\caption{The accuracy, CI, NIR, $p$-value, and Kappa statistic for each model when using all variables as input.}
	\label{tab:stats:reverse:all}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		Model & svmPoly & C5.0 & nb & nnet \\ \hline
		svmPoly & $100.0\%$ & $52.1222\%$ & $20.9548\%$ & $7.3681\%$ \\ \hline
		C5.0 & $52.1222\%$ & $100.0\%$ & $-8.1077\%$ & $14.9669\%$ \\ \hline
		nb & $20.9548\%$ & $-8.1077\%$ & $100.0\%$ & $28.9585\%$ \\ \hline
		nnet & $7.3681\%$ & $14.9669\%$ & $28.9585\%$ & $100.0\%$ \\ \hline
	\end{tabular}
	\caption{The model coorelation of an ansamble of 4 models when using all variables as input.}
	\label{tab:ansamble4:all}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Models & elapsed \\ \hline
		$4$ & $465.69$ \\ \hline
	\end{tabular}
	\caption{The time taken for all algorithm stages in seconds for an ansamble of 4 models when using all variables as input.}
	\label{tab:time:ansamble:all:4}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Models & $4$ \\ \hline
		elapsed & $465.69$ \\ \hline
	\end{tabular}
	\caption{The time taken for all algorithm stages in seconds for an ansamble of 4 models when using all variables as input.}
	\label{tab:time:ansamble:reverse:all:4}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		Model & svmPoly & C5.0 & nb & nnet & pls & fda & pcaNNet \\ \hline
		svmPoly & $100.0\%$ & $3.759\%$ & $6.9561\%$ & $3.8468\%$ & $41.4347\%$ & $-46.947\%$ & $69.1078\%$ \\ \hline
		C5.0 & $3.759\%$ & $100.0\%$ & $-2.5369\%$ & $-29.7641\%$ & $-6.8874\%$ & $-6.4685\%$ & $-38.4247\%$ \\ \hline
		nb & $6.9561\%$ & $-2.5369\%$ & $100.0\%$ & $8.0512\%$ & $11.8441\%$ & $17.0518\%$ & $8.5835\%$ \\ \hline
		nnet & $3.8468\%$ & $-29.7641\%$ & $8.0512\%$ & $100.0\%$ & $-11.8284\%$ & $-0.7218\%$ & $3.2346\%$ \\ \hline
		pls & $41.4347\%$ & $-6.8874\%$ & $11.8441\%$ & $-11.8284\%$ & $100.0\%$ & $20.5412\%$ & $23.9931\%$ \\ \hline
		fda & $-46.947\%$ & $-6.4685\%$ & $17.0518\%$ & $-0.7218\%$ & $20.5412\%$ & $100.0\%$ & $-25.4368\%$ \\ \hline
		pcaNNet & $69.1078\%$ & $-38.4247\%$ & $8.5835\%$ & $3.2346\%$ & $23.9931\%$ & $-25.4368\%$ & $100.0\%$ \\ \hline
	\end{tabular}
	\caption{The model coorelation of an ansamble of 7 models when using all variables as input.}
	\label{tab:ansamble7:all}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Models & elapsed \\ \hline
		$7$ & $497.25$ \\ \hline
	\end{tabular}
	\caption{The time taken for all algorithm stages in seconds for an ansamble of 7 models when using all variables as input.}
	\label{tab:time:ansamble:all:7}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Models & $7$ \\ \hline
		elapsed & $497.25$ \\ \hline
	\end{tabular}
	\caption{The time taken for all algorithm stages in seconds for an ansamble of 7 models when using all variables as input.}
	\label{tab:time:ansamble:reverse:all:7}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Models & elapsed \\ \hline
		$4$ & $465.69$ \\ \hline
		$7$ & $497.25$ \\ \hline
	\end{tabular}
	\caption{The time taken for all algorithm stages in seconds for an ansamble of different numbers of models when using all variables as input.}
	\label{tab:time:ansamble:all}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		Models & $4$ & $7$ \\ \hline
		elapsed & $465.69$ & $497.25$ \\ \hline
	\end{tabular}
	\caption{The time taken for all algorithm stages in seconds for an ansamble of different numbers of models when using all variables as input.}
	\label{tab:time:ansamble:reverse:all}
\end{table}
