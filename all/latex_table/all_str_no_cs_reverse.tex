\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{5}{|c|}{Reference} \\ \hline
		 Prediction & E & N & P & R & T \\ \hline
		 E & $0$ & $0$ & $0$ & $0$ & $0$ \\ \hline
		 N & $0$ & $1400$ & $0$ & $268$ & $0$ \\ \hline
		 P & $0$ & $99$ & $27$ & $0$ & $0$ \\ \hline
		 R & $0$ & $0$ & $0$ & $63$ & $0$ \\ \hline
		 T & $2$ & $0$ & $0$ & $40$ & $18$ \\ \hline
	\end{tabular}
	\caption{The confusion matrix for the polynomial SVM model when using all variables as input.}
	\label{tab:cm:all:svmPoly}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{7}{c|}{Statistics} \\ \hline
		Sen & Spec & PPV & NPV & DR & DP & BA \\ \hline
		$0\%$ & $100\%$ & NaN & $99.8957\%$ & $0\%$ & $0\%$ & $50\%$ \\ \hline
		$93.4\%$ & $35.89\%$ & $83.93\%$ & $60.24\%$ & $73.03\%$ & $87.01\%$ & $64.64\%$ \\ \hline
		$100\%$ & $94.762\%$ & $21.429\%$ & $100\%$ & $1.408\%$ & $6.573\%$ & $97.381\%$ \\ \hline
		$16.981\%$ & $100\%$ & $100\%$ & $83.387\%$ & $3.286\%$ & $3.286\%$ & $58.491\%$ \\ \hline
		$100\%$ & $97.788\%$ & $30\%$ & $100\%$ & $0.939\%$ & $3.13\%$ & $98.894\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the polynomial SVM model when using all variables as input.}
	\label{tab:cs:all:svmPoly}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{5}{|c|}{Reference} \\ \hline
		 Prediction & E & N & P & R & T \\ \hline
		 E & $1$ & $0$ & $0$ & $0$ & $0$ \\ \hline
		 N & $0$ & $1499$ & $0$ & $0$ & $0$ \\ \hline
		 P & $0$ & $0$ & $27$ & $0$ & $0$ \\ \hline
		 R & $0$ & $0$ & $0$ & $371$ & $0$ \\ \hline
		 T & $1$ & $0$ & $0$ & $0$ & $18$ \\ \hline
	\end{tabular}
	\caption{The confusion matrix for the decision tree model when using all variables as input.}
	\label{tab:cm:all:C5.0}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{7}{c|}{Statistics} \\ \hline
		Sen & Spec & PPV & NPV & DR & DP & BA \\ \hline
		$50\%$ & $100\%$ & $100\%$ & $99.9478\%$ & $0.0522\%$ & $0.0522\%$ & $75\%$ \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $78.2\%$ & $78.2\%$ & $100\%$ \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $1.408\%$ & $1.408\%$ & $100\%$ \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $19.35\%$ & $19.35\%$ & $100\%$ \\ \hline
		$100\%$ & $99.9473\%$ & $94.7368\%$ & $100\%$ & $0.939\%$ & $0.9911\%$ & $99.9737\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the decision tree model when using all variables as input.}
	\label{tab:cs:all:C5.0}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{5}{|c|}{Reference} \\ \hline
		 Prediction & E & N & P & R & T \\ \hline
		 E & $2$ & $0$ & $0$ & $0$ & $0$ \\ \hline
		 N & $0$ & $1492$ & $0$ & $1$ & $0$ \\ \hline
		 P & $0$ & $5$ & $27$ & $0$ & $0$ \\ \hline
		 R & $0$ & $2$ & $0$ & $369$ & $0$ \\ \hline
		 T & $0$ & $0$ & $0$ & $1$ & $18$ \\ \hline
	\end{tabular}
	\caption{The confusion matrix for the naive Bayes model when using all variables as input.}
	\label{tab:cm:all:nb}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{7}{c|}{Statistics} \\ \hline
		Sen & Spec & PPV & NPV & DR & DP & BA \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $0.1043\%$ & $0.1043\%$ & $100\%$ \\ \hline
		$99.53\%$ & $99.76\%$ & $99.93\%$ & $98.35\%$ & $77.83\%$ & $77.88\%$ & $99.65\%$ \\ \hline
		$100\%$ & $99.735\%$ & $84.375\%$ & $100\%$ & $1.408\%$ & $1.669\%$ & $99.868\%$ \\ \hline
		$99.46\%$ & $99.87\%$ & $99.46\%$ & $99.87\%$ & $19.25\%$ & $19.35\%$ & $99.67\%$ \\ \hline
		$100\%$ & $99.9473\%$ & $94.7368\%$ & $100\%$ & $0.939\%$ & $0.9911\%$ & $99.9737\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the naive Bayes model when using all variables as input.}
	\label{tab:cs:all:nb}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{5}{|c|}{Reference} \\ \hline
		 Prediction & E & N & P & R & T \\ \hline
		 E & $2$ & $0$ & $0$ & $0$ & $0$ \\ \hline
		 N & $0$ & $1499$ & $0$ & $0$ & $0$ \\ \hline
		 P & $0$ & $0$ & $27$ & $0$ & $0$ \\ \hline
		 R & $0$ & $0$ & $0$ & $371$ & $0$ \\ \hline
		 T & $0$ & $0$ & $0$ & $0$ & $18$ \\ \hline
	\end{tabular}
	\caption{The confusion matrix for the neural network model when using all variables as input.}
	\label{tab:cm:all:nnet}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{7}{c|}{Statistics} \\ \hline
		Sen & Spec & PPV & NPV & DR & DP & BA \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $0.1043\%$ & $0.1043\%$ & $100\%$ \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $78.2\%$ & $78.2\%$ & $100\%$ \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $1.408\%$ & $1.408\%$ & $100\%$ \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $19.35\%$ & $19.35\%$ & $100\%$ \\ \hline
		$100\%$ & $100\%$ & $100\%$ & $100\%$ & $0.939\%$ & $0.939\%$ & $100\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the neural network model when using all variables as input.}
	\label{tab:cs:all:nnet}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{5}{|c|}{Reference} \\ \hline
		 Prediction & E & N & P & R & T \\ \hline
		 E & $0$ & $0$ & $0$ & $0$ & $0$ \\ \hline
		 N & $0$ & $1498$ & $27$ & $103$ & $0$ \\ \hline
		 P & $0$ & $0$ & $0$ & $0$ & $0$ \\ \hline
		 R & $2$ & $1$ & $0$ & $268$ & $18$ \\ \hline
		 T & $0$ & $0$ & $0$ & $0$ & $0$ \\ \hline
	\end{tabular}
	\caption{The confusion matrix for the PLS model when using all variables as input.}
	\label{tab:cm:all:pls}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{7}{c|}{Statistics} \\ \hline
		Sen & Spec & PPV & NPV & DR & DP & BA \\ \hline
		$0\%$ & $100\%$ & NaN & $99.8957\%$ & $0\%$ & $0\%$ & $50\%$ \\ \hline
		$99.93\%$ & $68.9\%$ & $92.01\%$ & $99.65\%$ & $78.14\%$ & $84.92\%$ & $84.42\%$ \\ \hline
		$0\%$ & $100\%$ & NaN & $98.592\%$ & $0\%$ & $0\%$ & $50\%$ \\ \hline
		$72.24\%$ & $98.64\%$ & $92.73\%$ & $93.67\%$ & $13.98\%$ & $15.08\%$ & $85.44\%$ \\ \hline
		$0\%$ & $100\%$ & NaN & $99.061\%$ & $0\%$ & $0\%$ & $50\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the PLS model when using all variables as input.}
	\label{tab:cs:all:pls}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{5}{|c|}{Reference} \\ \hline
		 Prediction & E & N & P & R & T \\ \hline
		 E & $0$ & $0$ & $0$ & $0$ & $1$ \\ \hline
		 N & $0$ & $1411$ & $13$ & $69$ & $0$ \\ \hline
		 P & $0$ & $36$ & $14$ & $0$ & $0$ \\ \hline
		 R & $0$ & $51$ & $0$ & $294$ & $6$ \\ \hline
		 T & $2$ & $1$ & $0$ & $8$ & $11$ \\ \hline
	\end{tabular}
	\caption{The confusion matrix for the FDA model when using all variables as input.}
	\label{tab:cm:all:fda}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{7}{c|}{Statistics} \\ \hline
		Sen & Spec & PPV & NPV & DR & DP & BA \\ \hline
		$0\%$ & $99.9478\%$ & $0\%$ & $99.8956\%$ & $0\%$ & $0.0522\%$ & $49.9739\%$ \\ \hline
		$94.13\%$ & $80.38\%$ & $94.51\%$ & $79.25\%$ & $73.6\%$ & $77.88\%$ & $87.26\%$ \\ \hline
		$51.8519\%$ & $98.0952\%$ & $28\%$ & $99.3037\%$ & $0.7303\%$ & $2.6082\%$ & $74.9735\%$ \\ \hline
		$79.25\%$ & $96.31\%$ & $83.76\%$ & $95.08\%$ & $15.34\%$ & $18.31\%$ & $87.78\%$ \\ \hline
		$61.1111\%$ & $99.4207\%$ & $50\%$ & $99.6306\%$ & $0.5738\%$ & $1.1476\%$ & $80.2659\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the FDA model when using all variables as input.}
	\label{tab:cs:all:fda}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{5}{|c|}{Reference} \\ \hline
		 Prediction & E & N & P & R & T \\ \hline
		 E & $0$ & $0$ & $0$ & $0$ & $2$ \\ \hline
		 N & $0$ & $1499$ & $2$ & $1$ & $0$ \\ \hline
		 P & $0$ & $0$ & $25$ & $0$ & $0$ \\ \hline
		 R & $0$ & $0$ & $0$ & $370$ & $0$ \\ \hline
		 T & $2$ & $0$ & $0$ & $0$ & $16$ \\ \hline
	\end{tabular}
	\caption{The confusion matrix for the PCA neural network model when using all variables as input.}
	\label{tab:cm:all:pcaNNet}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{7}{c|}{Statistics} \\ \hline
		Sen & Spec & PPV & NPV & DR & DP & BA \\ \hline
		$0\%$ & $99.8956\%$ & $0\%$ & $99.8956\%$ & $0\%$ & $0.1043\%$ & $49.9478\%$ \\ \hline
		$100\%$ & $99.28\%$ & $99.8\%$ & $100\%$ & $78.2\%$ & $78.35\%$ & $99.64\%$ \\ \hline
		$92.593\%$ & $100\%$ & $100\%$ & $99.894\%$ & $1.304\%$ & $1.304\%$ & $96.296\%$ \\ \hline
		$99.73\%$ & $100\%$ & $100\%$ & $99.94\%$ & $19.3\%$ & $19.3\%$ & $99.87\%$ \\ \hline
		$88.8889\%$ & $99.8947\%$ & $88.8889\%$ & $99.8947\%$ & $0.8346\%$ & $0.939\%$ & $94.3918\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the PCA neural network model when using all variables as input.}
	\label{tab:cs:all:pcaNNet}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Model & elapsed \\ \hline
		svmPoly & $148.09$ \\ \hline
		C5.0 & $185.28$ \\ \hline
		nb & $204.35$ \\ \hline
		nnet & $581.90$ \\ \hline
		pls & $51.47$ \\ \hline
		fda & $55.38$ \\ \hline
		pcaNNet & $340.80$ \\ \hline
	\end{tabular}
	\caption{The train time in seconds for each model when using all variables as input.}
	\label{tab:time:all:train}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		Model & svmPoly & C5.0 & nb & nnet & pls & fda & pcaNNet \\ \hline
		elapsed & $148.09$ & $185.28$ & $204.35$ & $581.90$ & $51.47$ & $55.38$ & $340.80$ \\ \hline
	\end{tabular}
	\caption{The train time in seconds for each model when using all variables as input.}
	\label{tab:time:reverse:all:train}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Model & elapsed \\ \hline
		svmPoly & $0.20$ \\ \hline
		C5.0 & $0.08$ \\ \hline
		nb & $1.84$ \\ \hline
		nnet & $0.02$ \\ \hline
		pls & $0.35$ \\ \hline
		fda & $0.02$ \\ \hline
		pcaNNet & $0.02$ \\ \hline
	\end{tabular}
	\caption{The prediction time in seconds for each model when using all variables as input.}
	\label{tab:time:all:predict}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		Model & svmPoly & C5.0 & nb & nnet & pls & fda & pcaNNet \\ \hline
		elapsed & $0.20$ & $0.08$ & $1.84$ & $0.02$ & $0.35$ & $0.02$ & $0.02$ \\ \hline
	\end{tabular}
	\caption{The prediction time in seconds for each model when using all variables as input.}
	\label{tab:time:reverse:all:predict}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Model & elapsed \\ \hline
		svmPoly & NA \\ \hline
		C5.0 & $0$ \\ \hline
		nb & NA \\ \hline
		nnet & NA \\ \hline
		pls & $0.05$ \\ \hline
		fda & $0.04$ \\ \hline
		pcaNNet & NA \\ \hline
	\end{tabular}
	\caption{The variable importance calculation time in seconds for each model when using all variables as input.}
	\label{tab:time:all:importance}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		Model & svmPoly & C5.0 & nb & nnet & pls & fda & pcaNNet \\ \hline
		elapsed & NA & $0$ & NA & NA & $0.05$ & $0.04$ & NA \\ \hline
	\end{tabular}
	\caption{The variable importance calculation time in seconds for each model when using all variables as input.}
	\label{tab:time:reverse:all:importance}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Model & elapsed \\ \hline
		svmPoly & $148.72$ \\ \hline
		C5.0 & $186.08$ \\ \hline
		nb & $206.65$ \\ \hline
		nnet & $582.41$ \\ \hline
		pls & $52.59$ \\ \hline
		fda & $56.20$ \\ \hline
		pcaNNet & $341.32$ \\ \hline
	\end{tabular}
	\caption{The execution time in seconds for each model when using all variables as input.}
	\label{tab:time:all:total}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		Model & svmPoly & C5.0 & nb & nnet & pls & fda & pcaNNet \\ \hline
		elapsed & $148.72$ & $186.08$ & $206.65$ & $582.41$ & $52.59$ & $56.20$ & $341.32$ \\ \hline
	\end{tabular}
	\caption{The execution time in seconds for each model when using all variables as input.}
	\label{tab:time:reverse:all:total}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		Model & elapsed_train & elapsed_predict & elapsed_importance & elapsed_total \\ \hline
		svmPoly & $148.09$ & $0.20$ & NA & $148.72$ \\ \hline
		C5.0 & $185.28$ & $0.08$ & $0$ & $186.08$ \\ \hline
		nb & $204.35$ & $1.84$ & NA & $206.65$ \\ \hline
		nnet & $581.90$ & $0.02$ & NA & $582.41$ \\ \hline
		pls & $51.47$ & $0.35$ & $0.05$ & $52.59$ \\ \hline
		fda & $55.38$ & $0.02$ & $0.04$ & $56.20$ \\ \hline
		pcaNNet & $340.80$ & $0.02$ & NA & $341.32$ \\ \hline
	\end{tabular}
	\caption{The time taken for all algorithm stages in seconds for each model when using all variables as input.}
	\label{tab:time:all}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		Model & svmPoly & C5.0 & nb & nnet & pls & fda & pcaNNet \\ \hline
		elapsed_train & $148.09$ & $185.28$ & $204.35$ & $581.90$ & $51.47$ & $55.38$ & $340.80$ \\ \hline
		elapsed_predict & $0.20$ & $0.08$ & $1.84$ & $0.02$ & $0.35$ & $0.02$ & $0.02$ \\ \hline
		elapsed_importance & NA & $0$ & NA & NA & $0.05$ & $0.04$ & NA \\ \hline
		elapsed_total & $148.72$ & $186.08$ & $206.65$ & $582.41$ & $52.59$ & $56.20$ & $341.32$ \\ \hline
	\end{tabular}
	\caption{The time taken for all algorithm stages in seconds for each model when using all variables as input.}
	\label{tab:time:reverse:all}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		Metric & svmPoly & C5.0 & nb & nnet & pls & fda & pcaNNet \\ \hline
		Acc & $0.7866$ & $0.9995$ & $0.9953$ & $1$ & $0.9212$ & $0.9025$ & $0.9963$ \\ \hline
		$95\%$ CI & $(0.7676, 0.8048)$ & $(0.9971, 1)$ & $(0.9911, 0.9979)$ & $(0.9981, 1)$ & $(0.9083, 0.9329)$ & $(0.8883, 0.9154)$ & $(0.9925, 0.9985)$ \\ \hline
		NIR & $0.782$ & $0.782$ & $0.782$ & $0.782$ & $0.782$ & $0.782$ & $0.782$ \\ \hline
		$p$-value & $0.3206$ & $< 2.2 \times {10}^{-16}$ & $< 2.2 \times {10}^{-16}$ & $< 2.2 \times {10}^{-16}$ & $< 2.2 \times {10}^{-16}$ & $< 2.2 \times {10}^{-16}$ & $< 2.2 \times {10}^{-16}$ \\ \hline
		Kappa & $0.3163$ & $0.9985$ & $0.9867$ & $1$ & $0.7432$ & $0.7253$ & $0.9896$ \\ \hline
	\end{tabular}
	\caption{The accuracy, CI, NIR, $p$-value, and Kappa statistic for each model when using all variables as input.}
	\label{tab:stats:all}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		Model & Acc & $95\%$ CI & NIR & $p$-value & Kappa \\ \hline
		svmPoly & $0.7866$ & $(0.7676, 0.8048)$ & $0.782$ & $0.3206$ & $0.3163$ \\ \hline
		C5.0 & $0.9995$ & $(0.9971, 1)$ & $0.782$ & $< 2.2 \times {10}^{-16}$ & $0.9985$ \\ \hline
		nb & $0.9953$ & $(0.9911, 0.9979)$ & $0.782$ & $< 2.2 \times {10}^{-16}$ & $0.9867$ \\ \hline
		nnet & $1$ & $(0.9981, 1)$ & $0.782$ & $< 2.2 \times {10}^{-16}$ & $1$ \\ \hline
		pls & $0.9212$ & $(0.9083, 0.9329)$ & $0.782$ & $< 2.2 \times {10}^{-16}$ & $0.7432$ \\ \hline
		fda & $0.9025$ & $(0.8883, 0.9154)$ & $0.782$ & $< 2.2 \times {10}^{-16}$ & $0.7253$ \\ \hline
		pcaNNet & $0.9963$ & $(0.9925, 0.9985)$ & $0.782$ & $< 2.2 \times {10}^{-16}$ & $0.9896$ \\ \hline
	\end{tabular}
	\caption{The accuracy, CI, NIR, $p$-value, and Kappa statistic for each model when using all variables as input.}
	\label{tab:stats:reverse:all}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|}
		\hline
		Models \\ \hline
	\end{tabular}
	\caption{The accuracy, CI, NIR, $p$-value, and Kappa statistic for each model when using all variables as input.}
	\label{tab:time:ansamble:all}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|}
		\hline
		Models \\ \hline
	\end{tabular}
	\caption{The time taken for all algorithm stages in seconds for an ansamble of different numbers of models when using all variables as input.}
	\label{tab:time:ansamble:reverse:all}
\end{table}
