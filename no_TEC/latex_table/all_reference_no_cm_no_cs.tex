\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{5}{c|}{Class} \\ \hline
		Statistics & E & N & P & R & T \\ \hline
		Sen & $0\%$ & $98.63\%$ & $3.7037\%$ & $3.1662\%$ & $63.1579\%$ \\ \hline
		Spec & $100\%$ & $10.75\%$ & $99.4271\%$ & $99.6719\%$ & $98.4801\%$ \\ \hline
		PPV & NaN & $75.13\%$ & $10\%$ & $75\%$ & $33.3333\%$ \\ \hline
		NPV & $99.8123\%$ & $74.19\%$ & $98.3627\%$ & $76.8015\%$ & $99.5519\%$ \\ \hline
		DR & $0\%$ & $72.22\%$ & $0.0626\%$ & $0.7509\%$ & $0.7509\%$ \\ \hline
		DP & $0\%$ & $96.12\%$ & $0.6258\%$ & $1.0013\%$ & $2.2528\%$ \\ \hline
		BA & $50\%$ & $54.69\%$ & $51.5654\%$ & $51.419\%$ & $80.819\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the polynomial SVM model when using all variables except Dst, TEC, and dTEC as input.}
	\label{tab:cs:reverse:noTEC:svmPoly}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{5}{c|}{Class} \\ \hline
		Statistics & E & N & P & R & T \\ \hline
		Sen & $33.3333\%$ & $93.76\%$ & $0\%$ & $64.91\%$ & $31.5789\%$ \\ \hline
		Spec & $100\%$ & $63.55\%$ & $100\%$ & $93.11\%$ & $99.4934\%$ \\ \hline
		PPV & $100\%$ & $87.55\%$ & NaN & $74.55\%$ & $42.8571\%$ \\ \hline
		NPV & $99.8748\%$ & $78.84\%$ & $98.31\%$ & $89.51\%$ & $99.1793\%$ \\ \hline
		DR & $0.0626\%$ & $68.65\%$ & $0\%$ & $15.39\%$ & $0.3755\%$ \\ \hline
		DP & $0.0626\%$ & $78.41\%$ & $0\%$ & $20.65\%$ & $0.8761\%$ \\ \hline
		BA & $66.6667\%$ & $78.66\%$ & $50\%$ & $79.01\%$ & $65.5361\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the decision tree model when using all variables except Dst, TEC, and dTEC as input.}
	\label{tab:cs:reverse:noTEC:C5.0}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{5}{c|}{Class} \\ \hline
		Statistics & E & N & P & R & T \\ \hline
		Sen & $100\%$ & $100\%$ & $100\%$ & $100\%$ & $100\%$ \\ \hline
		Spec & $100\%$ & $100\%$ & $100\%$ & $100\%$ & $100\%$ \\ \hline
		PPV & $100\%$ & $100\%$ & $100\%$ & $100\%$ & $100\%$ \\ \hline
		NPV & $100\%$ & $100\%$ & $100\%$ & $100\%$ & $100\%$ \\ \hline
		DR & $0.1877\%$ & $73.22\%$ & $1.69\%$ & $23.72\%$ & $1.189\%$ \\ \hline
		DP & $0.1877\%$ & $73.22\%$ & $1.69\%$ & $23.72\%$ & $1.189\%$ \\ \hline
		BA & $100\%$ & $100\%$ & $100\%$ & $100\%$ & $100\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the naive Bayes model when using all variables except Dst, TEC, and dTEC as input.}
	\label{tab:cs:reverse:noTEC:nb}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{5}{c|}{Class} \\ \hline
		Statistics & E & N & P & R & T \\ \hline
		Sen & $100\%$ & $100\%$ & $100\%$ & $100\%$ & $100\%$ \\ \hline
		Spec & $100\%$ & $100\%$ & $100\%$ & $100\%$ & $100\%$ \\ \hline
		PPV & $100\%$ & $100\%$ & $100\%$ & $100\%$ & $100\%$ \\ \hline
		NPV & $100\%$ & $100\%$ & $100\%$ & $100\%$ & $100\%$ \\ \hline
		DR & $0.1877\%$ & $73.22\%$ & $1.69\%$ & $23.72\%$ & $1.189\%$ \\ \hline
		DP & $0.1877\%$ & $73.22\%$ & $1.69\%$ & $23.72\%$ & $1.189\%$ \\ \hline
		BA & $100\%$ & $100\%$ & $100\%$ & $100\%$ & $100\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the neural network model when using all variables except Dst, TEC, and dTEC as input.}
	\label{tab:cs:reverse:noTEC:nnet}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{5}{c|}{Class} \\ \hline
		Statistics & E & N & P & R & T \\ \hline
		Sen & $0\%$ & $96.92\%$ & $0\%$ & $34.83\%$ & $0\%$ \\ \hline
		Spec & $100\%$ & $35.75\%$ & $100\%$ & $95.32\%$ & $100\%$ \\ \hline
		PPV & NaN & $80.48\%$ & NaN & $69.84\%$ & NaN \\ \hline
		NPV & $99.8123\%$ & $80.95\%$ & $98.31\%$ & $82.47\%$ & $98.811\%$ \\ \hline
		DR & $0\%$ & $70.96\%$ & $0\%$ & $8.26\%$ & $0\%$ \\ \hline
		DP & $0\%$ & $88.17\%$ & $0\%$ & $11.83\%$ & $0\%$ \\ \hline
		BA & $50\%$ & $66.34\%$ & $50\%$ & $65.08\%$ & $50\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the PLS model when using all variables except Dst, TEC, and dTEC as input.}
	\label{tab:cs:reverse:noTEC:pls}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{5}{c|}{Class} \\ \hline
		Statistics & E & N & P & R & T \\ \hline
		Sen & $33.3333\%$ & $92.48\%$ & $7.4074\%$ & $56.2\%$ & $36.842\%$ \\ \hline
		Spec & $100\%$ & $56.78\%$ & $99.7454\%$ & $92.21\%$ & $99.43\%$ \\ \hline
		PPV & $100\%$ & $85.4\%$ & $33.3333\%$ & $69.16\%$ & $43.75\%$ \\ \hline
		NPV & $99.8748\%$ & $73.41\%$ & $98.4296\%$ & $87.13\%$ & $99.241\%$ \\ \hline
		DR & $0.0626\%$ & $67.71\%$ & $0.1252\%$ & $13.33\%$ & $0.438\%$ \\ \hline
		DP & $0.0626\%$ & $79.29\%$ & $0.3755\%$ & $19.27\%$ & $1.001\%$ \\ \hline
		BA & $66.6667\%$ & $74.63\%$ & $53.5764\%$ & $74.2\%$ & $68.136\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the FDA model when using all variables except Dst, TEC, and dTEC as input.}
	\label{tab:cs:reverse:noTEC:fda}
\end{table}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		 & \multicolumn{5}{c|}{Class} \\ \hline
		Statistics & E & N & P & R & T \\ \hline
		Sen & $0\%$ & $93.68\%$ & $0\%$ & $63.85\%$ & $5.2632\%$ \\ \hline
		Spec & $100\%$ & $61.45\%$ & $100\%$ & $92.29\%$ & $100\%$ \\ \hline
		PPV & NaN & $86.92\%$ & NaN & $72.02\%$ & $100\%$ \\ \hline
		NPV & $99.8123\%$ & $78.04\%$ & $98.31\%$ & $89.14\%$ & $98.8729\%$ \\ \hline
		DR & $0\%$ & $68.59\%$ & $0\%$ & $15.14\%$ & $0.0626\%$ \\ \hline
		DP & $0\%$ & $78.91\%$ & $0\%$ & $21.03\%$ & $0.0626\%$ \\ \hline
		BA & $50\%$ & $77.56\%$ & $50\%$ & $78.07\%$ & $52.6316\%$ \\ \hline
	\end{tabular}
	\caption{The performance indicators derived from the confusion matrix for the PCA neural network model when using all variables except Dst, TEC, and dTEC as input.}
	\label{tab:cs:reverse:noTEC:pcaNNet}
\end{table}
